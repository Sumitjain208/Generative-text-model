{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943f7af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Text Generation Demo\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates how to use the text generation models implemented in this project. It includes loading the models, preprocessing input data, and generating text samples.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"load-models\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import required libraries\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from utils.text_preprocessing import TextPreprocessor\\n\",\n",
    "    \"from models.lstm_model import LSTMTextGenerator, TextDataset, train_lstm_model\\n\",\n",
    "    \"from models.gpt_model import GPTTextGenerator\\n\",\n",
    "    \"from torch.utils.data import DataLoader\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Libraries imported successfully!\\\")\\n\",\n",
    "    \"print(f\\\"PyTorch version: {torch.__version__}\\\")\\n\",\n",
    "    \"print(f\\\"CUDA available: {torch.cuda.is_available()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"preprocess-data\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load sample data\\n\",\n",
    "    \"def load_sample_data():\\n\",\n",
    "    \"    sample_texts = [\\n\",\n",
    "    \"        \\\"Technology is rapidly evolving and changing our daily lives. Artificial intelligence and machine learning are becoming integral parts of modern society. Smart devices connect us globally while automation increases efficiency in various industries.\\\",\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        \\\"Climate change represents one of the most pressing challenges of our time. Rising temperatures affect weather patterns worldwide. Sustainable energy solutions and environmental conservation efforts are crucial for future generations.\\\",\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        \\\"Space exploration continues to fascinate humanity and drive scientific advancement. Recent missions to Mars have provided valuable insights about our neighboring planet. Private companies are now contributing significantly to space research and development.\\\",\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        \\\"Education systems worldwide are adapting to digital transformation. Online learning platforms provide accessible education to students globally. Interactive technologies enhance traditional teaching methods and improve learning outcomes.\\\",\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        \\\"Healthcare innovation saves lives and improves quality of life for millions. Medical research leads to breakthrough treatments for various diseases. Personalized medicine and genetic therapies represent the future of healthcare.\\\"\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"    return sample_texts\\n\",\n",
    "    \"\\n\",\n",
    "    \"texts = load_sample_data()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Sample Data Loaded:\\\")\\n\",\n",
    "    \"print(f\\\"Number of texts: {len(texts)}\\\")\\n\",\n",
    "    \"print(f\\\"Average text length: {np.mean([len(text) for text in texts]):.1f} characters\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display first text\\n\",\n",
    "    \"print(f\\\"\\\\nFirst text sample:\\\\n{texts[0]}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"id\": \"generate-text\"\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize preprocessor\\n\",\n",
    "    \"preprocessor = TextPreprocessor()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Build vocabulary\\n\",\n",
    "    \"vocab = preprocessor.build_vocabulary(texts, min_freq=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Vocabulary size: {len(vocab)}\\\")\\n\",\n",
    "    \"print(f\\\"Sample vocabulary items: {list(vocab.items())[:10]}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create sequences\\n\",\n",
    "    \"sequences = preprocessor.create_sequences(texts, sequence_length=15)\\n\",\n",
    "    \"print(f\\\"Number of training sequences: {len(sequences)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show sample sequence\\n\",\n",
    "    \"sample_seq = sequences[0]\\n\",\n",
    "    \"print(f\\\"\\\\nSample sequence (indices): {sample_seq}\\\")\\n\",\n",
    "    \"print(f\\\"Sample sequence (words): {preprocessor.sequence_to_text(sample_seq)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create dataset and dataloader\\n\",\n",
    "    \"dataset = TextDataset(sequences, sequence_length=15)\\n\",\n",
    "    \"dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize LSTM model\\n\",\n",
    "    \"lstm_model = LSTMTextGenerator(\\n\",\n",
    "    \"    vocab_size=preprocessor.vocab_size,\\n\",\n",
    "    \"    embedding_dim=64,\\n\",\n",
    "    \"    hidden_dim=128,\\n\",\n",
    "    \"    num_layers=2,\\n\",\n",
    "    \"    dropout=0.2\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"LSTM Model Architecture:\\\")\\n\",\n",
    "    \"print(lstm_model)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train the model\\n\",\n",
    "    \"print(\\\"\\\\nTraining LSTM model...\\\")\\n\",\n",
    "    \"losses = train_lstm_model(lstm_model, dataloader, num_epochs=10, learning_rate=0.01)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot training loss\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"plt.plot(losses, marker='o', linewidth=2, markersize=6)\\n\",\n",
    "    \"plt.title('LSTM Training Loss Over Time', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Epoch', fontsize=12)\\n\",\n",
    "    \"plt.ylabel('Loss', fontsize=12)\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Final training loss: {losses[-1]:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate text with different prompts\\n\",\n",
    "    \"prompts = [\\n\",\n",
    "    \"    \\\"Technology\\\",\\n\",\n",
    "    \"    \\\"Climate change\\\",\\n\",\n",
    "    \"    \\\"Space\\\",\\n\",\n",
    "    \"    \\\"Education\\\",\\n\",\n",
    "    \"    \\\"Healthcare innovation\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"LSTM Generated Text:\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, prompt in enumerate(prompts, 1):\\n\",\n",
    "    \"    generated = lstm_model.generate_text(\\n\",\n",
    "    \"        preprocessor, \\n\",\n",
    "    \"        start_text=prompt, \\n\",\n",
    "    \"        max_length=40,\\n\",\n",
    "    \"        temperature=0.8\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"{i}. Prompt: '{prompt}'\\\")\\n\",\n",
    "    \"    print(f\\\"   Generated: {generated}\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 50)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize GPT model\\n\",\n",
    "    \"print(\\\"Loading GPT-2 model...\\\")\\n\",\n",
    "    \"gpt_generator = GPTTextGenerator('gpt2')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate text with GPT\\n\",\n",
    "    \"print(\\\"\\\\nGPT-2 Generated Text:\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"gpt_prompts = [\\n\",\n",
    "    \"    \\\"Technology is revolutionizing\\\",\\n\",\n",
    "    \"    \\\"Climate change impacts our\\\",\\n\",\n",
    "    \"    \\\"Space exploration reveals new\\\",\\n\",\n",
    "    \"    \\\"Modern education systems are\\\",\\n\",\n",
    "    \"    \\\"Healthcare innovations provide\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, prompt in enumerate(gpt_prompts, 1):\\n\",\n",
    "    \"    generated_texts = gpt_generator.generate_text(\\n\",\n",
    "    \"        prompt=prompt,\\n\",\n",
    "    \"        max_length=60,\\n\",\n",
    "    \"        temperature=0.7,\\n\",\n",
    "    \"        num_return_sequences=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"{i}. Prompt: '{prompt}'\\\")\\n\",\n",
    "    \"    print(f\\\"   Generated: {generated_texts[0]}\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 50)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compare both models on the same prompts\\n\",\n",
    "    \"comparison_prompts = [\\\"Technology\\\", \\\"Climate\\\", \\\"Space\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Model Comparison:\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for prompt in comparison_prompts:\\n\",\n",
    "    \"    print(f\\\"\\\\nPrompt: '{prompt}'\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 30)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # LSTM generation\\n\",\n",
    "    \"    lstm_generated = lstm_model.generate_text(\\n\",\n",
    "    \"        preprocessor, \\n\",\n",
    "    \"        start_text=prompt, \\n\",\n",
    "    \"        max_length=30,\\n\",\n",
    "    \"        temperature=0.8\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # GPT generation\\n\",\n",
    "    \"    gpt_generated = gpt_generator.generate_text(\\n\",\n",
    "    \"        prompt=prompt,\\n\",\n",
    "    \"        max_length=50,\\n\",\n",
    "    \"        temperature=0.8\\n\",\n",
    "    \"    )[0]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"LSTM: {lstm_generated}\\\")\\n\",\n",
    "    \"    print(f\\\"GPT:  {gpt_generated}\\\")\\n\",\n",
    "    \"    print(\\\"=\\\" * 60)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def interactive_text_generation():\\n\",\n",
    "    \"    \\\"\\\"\\\"Interactive function for text generation\\\"\\\"\\\"\\n\",\n",
    "    \"    print(\\\"Interactive Text Generation\\\")\\n\",\n",
    "    \"    print(\\\"Enter your prompts below (type 'stop' to end)\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    while True:\\n\",\n",
    "    \"        user_prompt = input(\\\"\\\\nEnter your prompt: \\\").strip()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if user_prompt.lower() == 'stop':\\n\",\n",
    "    \"            break\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        if not user_prompt:\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        print(\\\"\\\\nChoose model: 1) LSTM  2) GPT  3) Both\\\")\\n\",\n",
    "    \"        model_choice = input(\\\"Enter choice (1, 2, or 3): \\\").strip()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if model_choice in ['1', '3']:\\n\",\n",
    "    \"            lstm_result = lstm_model.generate_text(\\n\",\n",
    "    \"                preprocessor, \\n\",\n",
    "    \"                start_text=user_prompt, \\n\",\n",
    "    \"                max_length=40,\\n\",\n",
    "    \"                temperature=0.8\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"            print(f\\\"\\\\nLSTM Result: {lstm_result}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if model_choice in ['2', '3']:\\n\",\n",
    "    \"            gpt_result = gpt_generator.generate_text(\\n\",\n",
    "    \"                prompt=user_prompt,\\n\",\n",
    "    \"                max_length=60,\\n\",\n",
    "    \"                temperature=0.8\\n\",\n",
    "    \"            )[0]\\n\",\n",
    "    \"            print(f\\\"\\\\nGPT Result: {gpt_result}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Uncomment the line below to run interactive generation\\n\",\n",
    "    \"# interactive_text_generation()\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.11.9\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
